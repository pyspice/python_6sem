{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier as NBC\n",
    "from nltk.tokenize import word_tokenize\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sheet = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        self.category_priors = category_priors        \n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "        \n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = defaultdict(Counter)\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = Counter()\n",
    "\n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = Counter()\n",
    "        \n",
    "        # Categories names\n",
    "        self.categories = None\n",
    "\n",
    "        # Total number of features in categories and at all\n",
    "        self.features = None\n",
    "        self.category_features = Counter()\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_train : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(x_train, str):\n",
    "            x_train = [x_train]\n",
    "            \n",
    "        for i in range(len(x_train)):\n",
    "            if isinstance(x_train[i], str):\n",
    "                x_train[i] = [x_train[i]]\n",
    "                \n",
    "            line = []\n",
    "            for j in x_train[i]:\n",
    "                line.extend(j.split())\n",
    "                \n",
    "            x_train[i] = line\n",
    "        \n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        for i in range(len(y_train)):\n",
    "            self.feature_category_counts[y_train[i]].update(x_train[i])\n",
    "            self.feature_counts.update(x_train[i])\n",
    "        self.category_doc_counts.update(y_train)\n",
    "        \n",
    "        self.categories = list(self.category_doc_counts.keys())\n",
    "        \n",
    "        self.features = sum(list(self.feature_counts.values()))\n",
    "        for cat_name in self.get_categories():\n",
    "            self.category_features[cat_name] = sum(list(self.feature_category_counts[cat_name].values()))\n",
    "        \n",
    "        # Если априорные вероятности категорий не заданы, то надо аппроксимировать их\n",
    "        if self.category_priors is None:\n",
    "            self.category_priors = dict()\n",
    "            for cat_name in self.get_categories():\n",
    "                self.category_priors[cat_name] = self.category_features[cat_name] / self.features\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        \n",
    "        categories = []\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "            \n",
    "        for i in range(len(text)):\n",
    "            if isinstance(text[i], str):\n",
    "                text[i] = [text[i]]\n",
    "                \n",
    "            line = []\n",
    "            for j in text[i]:\n",
    "                line.extend(j.split())\n",
    "            \n",
    "            probs = self.get_probs(line)\n",
    "            argmax = 0\n",
    "            for i in range(len(probs)):\n",
    "                if probs[i] > probs[argmax]:\n",
    "                    argmax = i\n",
    "                    \n",
    "            categories.append(list(self.get_categories())[argmax])\n",
    "                \n",
    "        return categories\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        \"\"\"\n",
    "        Возвращает точность предсказаний на text для правильных категорий labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "        labels : list of str\n",
    "            Список категорий для каждого токена из text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : float\n",
    "            Точность предсказания.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "            \n",
    "        for i in range(len(text)):\n",
    "            if isinstance(text[i], str):\n",
    "                text[i] = [text[i]]\n",
    "                \n",
    "            line = []\n",
    "            for j in text[i]:\n",
    "                line.extend(j.split())\n",
    "                \n",
    "        categories = self.predict(text)        \n",
    "        accurate = np.where(categories == labels)\n",
    "        \n",
    "        return len(accurate[0]) / len(labels)\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = text.split()\n",
    "\n",
    "        return [self.get_category_prob(cat_name, text) for cat_name in self.get_categories()]\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятность принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        log_prob = log(self.category_priors[cat])\n",
    "        for word in text:\n",
    "            weighted_prob = self.get_weighted_feature_prob(cat, word)\n",
    "            if weighted_prob == 0:\n",
    "                weighted_prob = self.supposed_prob\n",
    "            log_prob += log(weighted_prob)\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        \"\"\"\n",
    "        Вычисляет взвешенную вероятность P(Слово|Категория).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        feature : str\n",
    "            Слово из текста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Возвращает взвешенную вероятность слова feature при условии категории cat.\n",
    "        \"\"\"\n",
    "        unweighted_prob = self.feature_category_counts[cat][feature] / self.category_features[cat]\n",
    "        return (self.weight * self.supposed_prob + self.features * unweighted_prob) / (self.weight + self.features)\n",
    "\n",
    "    def get_categories(self):\n",
    "        \"\"\"\n",
    "        Возвращает список названий всех категорий.\n",
    "        Returns\n",
    "        -------\n",
    "        cat_list : list of str\n",
    "        \"\"\"\n",
    "        return self.categories\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2893/2893 [00:00<00:00, 5021.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Предобработка данных для классификатора nltk, если требуется\n",
    "labels = sheet.values[:, 0]\n",
    "msgs0 = sheet.values[:, 1]\n",
    "words = set()\n",
    "msgs = []\n",
    "msgwords = [set() for i in range(len(msgs0))]\n",
    "for i in tqdm(range(len(msgs0))):\n",
    "    msgs.append(msgs0[i].split())\n",
    "    msgwords[i].update(msgs[i])\n",
    "    words.update(msgs[i])\n",
    "    \n",
    "labels = np.array(labels)\n",
    "msgs = np.array(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2893/2893 [00:00<00:00, 11225.63it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in tqdm(range(len(msgs))):\n",
    "    data.append(np.array((Counter(msgs[i]), labels[i])))\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:37<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "splits = KFold(len(msgs), n_folds=10, shuffle=True)\n",
    "nltk_accs = []\n",
    "for train_index, test_index in tqdm(list(splits)):\n",
    "    y_test = labels[test_index]\n",
    "    \n",
    "    data_train = data[train_index]\n",
    "    data_test = data[test_index, 0]\n",
    "    \n",
    "    nltk_classifier = NBC.train(data_train)\n",
    "    \n",
    "    nltk_pred = nltk_classifier.classify_many(data_test)\n",
    "    \n",
    "    nltk_acc = accuracy_score(nltk_pred, y_test)\n",
    "    \n",
    "    nltk_accs.append(nltk_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "accs = []\n",
    "for train_index, test_index in tqdm(list(splits)):\n",
    "    x_train, x_test = msgs[train_index], msgs[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    data_train = data[train_index]\n",
    "    data_test = data[test_index, 0]\n",
    "    \n",
    "    classifier = NaiveBayes()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    pred = classifier.predict(x_test)\n",
    "    \n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    \n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98965517241379308, 0.98965517241379308, 0.97931034482758617, 0.99307958477508651, 0.97577854671280273, 0.98961937716262971, 0.97577854671280273, 0.98615916955017302, 0.9965397923875432, 0.99307958477508651]\n",
      "[0.95517241379310347, 0.95517241379310347, 0.9517241379310345, 0.94809688581314877, 0.97923875432525953, 0.96885813148788924, 0.95847750865051906, 0.96539792387543255, 0.97923875432525953, 0.98615916955017302]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(nltk_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG7WKPh/KoEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b4d2865518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_data = pd.DataFrame(np.array([accs, nltk_accs]).T, columns=['yours', 'nltk'])\n",
    "ax = plt_data.boxplot(figsize=(40, 40), return_type='axes', sym='k.')\n",
    "\n",
    "_ = plt.setp(ax.lines, linewidth=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
