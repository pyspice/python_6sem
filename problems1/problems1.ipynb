{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier as NBC\n",
    "from nltk.tokenize import word_tokenize\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sheet = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        self.category_priors = category_priors        \n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "        \n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = defaultdict(Counter)\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = Counter()\n",
    "\n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = Counter()\n",
    "        \n",
    "        # Categories names\n",
    "        self.categories = None\n",
    "\n",
    "        # Total number of features in categories and at all\n",
    "        self.features = None\n",
    "        self.category_features = Counter()\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_train : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(x_train, str):\n",
    "            x_train = [x_train]\n",
    "            \n",
    "        for i in range(len(x_train)):\n",
    "            if isinstance(x_train[i], str):\n",
    "                x_train[i] = [x_train[i]]\n",
    "                \n",
    "            line = []\n",
    "            for j in x_train[i]:\n",
    "                line.extend(j.split())\n",
    "                \n",
    "            x_train[i] = line\n",
    "        \n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        for i in range(len(y_train)):\n",
    "            self.feature_category_counts[y_train[i]].update(x_train[i])\n",
    "            self.feature_counts.update(x_train[i])\n",
    "        self.category_doc_counts.update(y_train)\n",
    "        \n",
    "        self.categories = list(self.category_doc_counts.keys())\n",
    "        \n",
    "        self.features = sum(list(self.feature_counts.values()))\n",
    "        for cat_name in self.get_categories():\n",
    "            self.category_features[cat_name] = sum(list(self.feature_category_counts[cat_name].values()))\n",
    "        \n",
    "        # Если априорные вероятности категорий не заданы, то надо аппроксимировать их\n",
    "        if self.category_priors is None:\n",
    "            self.category_priors = dict()\n",
    "            for cat_name in self.get_categories():\n",
    "                self.category_priors[cat_name] = self.category_features[cat_name] / self.features\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        \n",
    "        categories = []\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "            \n",
    "        for i in range(len(text)):\n",
    "            if isinstance(text[i], str):\n",
    "                text[i] = [text[i]]\n",
    "                \n",
    "            line = []\n",
    "            for j in text[i]:\n",
    "                line.extend(j.split())\n",
    "            \n",
    "            probs = self.get_probs(line)\n",
    "            argmax = 0\n",
    "            for i in range(len(probs)):\n",
    "                if probs[i] > probs[argmax]:\n",
    "                    argmax = i\n",
    "                    \n",
    "            categories.append(list(self.get_categories())[argmax])\n",
    "                \n",
    "        return categories\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        \"\"\"\n",
    "        Возвращает точность предсказаний на text для правильных категорий labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "        labels : list of str\n",
    "            Список категорий для каждого токена из text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : float\n",
    "            Точность предсказания.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "            \n",
    "        for i in range(len(text)):\n",
    "            if isinstance(text[i], str):\n",
    "                text[i] = [text[i]]\n",
    "                \n",
    "            line = []\n",
    "            for j in text[i]:\n",
    "                line.extend(j.split())\n",
    "                \n",
    "        categories = self.predict(text)        \n",
    "        accurate = np.where(categories == labels)\n",
    "        \n",
    "        return len(accurate[0]) / len(labels)\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = text.split()\n",
    "\n",
    "        return [self.get_category_prob(cat_name, text) for cat_name in self.get_categories()]\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятность принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        log_prob = log(self.category_priors[cat])\n",
    "        for word in text:\n",
    "            weighted_prob = self.get_weighted_feature_prob(cat, word)\n",
    "            if weighted_prob == 0:\n",
    "                weighted_prob = self.supposed_prob\n",
    "            log_prob += log(weighted_prob)\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        \"\"\"\n",
    "        Вычисляет взвешенную вероятность P(Слово|Категория).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        feature : str\n",
    "            Слово из текста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Возвращает взвешенную вероятность слова feature при условии категории cat.\n",
    "        \"\"\"\n",
    "        unweighted_prob = self.feature_category_counts[cat][feature] / self.category_features[cat]\n",
    "        return (self.weight * self.supposed_prob + self.features * unweighted_prob) / (self.weight + self.features)\n",
    "\n",
    "    def get_categories(self):\n",
    "        \"\"\"\n",
    "        Возвращает список названий всех категорий.\n",
    "        Returns\n",
    "        -------\n",
    "        cat_list : list of str\n",
    "        \"\"\"\n",
    "        return self.categories\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2893/2893 [00:00<00:00, 7649.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Предобработка данных для классификатора nltk, если требуется\n",
    "labels = sheet.values[:, 0]\n",
    "msgs0 = sheet.values[:, 1]\n",
    "words = set()\n",
    "msgs = []\n",
    "msgwords = [set() for i in range(len(msgs0))]\n",
    "for i in tqdm(range(len(msgs0))):\n",
    "    msgs.append(msgs0[i].split())\n",
    "    msgwords[i].update(msgs[i])\n",
    "    words.update(msgs[i])\n",
    "    \n",
    "labels = np.array(labels)\n",
    "msgs = np.array(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2893/2893 [00:59<00:00, 48.48it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in tqdm(range(len(msgs))):\n",
    "    data.append(({word: (word in msgwords[i]) for word in words}, labels[i]))\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [1:22:11<00:00, 493.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "splits = KFold(len(msgs), n_folds=10, shuffle=True)\n",
    "nltk_accs = []\n",
    "for train_index, test_index in tqdm(list(splits)):\n",
    "    x_train, x_test = msgs[train_index], msgs[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    data_train = data[train_index]\n",
    "    data_test = data[test_index, 0]\n",
    "    \n",
    "    nltk_classifier = NBC.train(data_train)\n",
    "    \n",
    "    nltk_pred = nltk_classifier.classify_many(data_test)\n",
    "    \n",
    "    nltk_acc = accuracy_score(nltk_pred, y_test)\n",
    "    \n",
    "    nltk_accs.append(nltk_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "accs = []\n",
    "for train_index, test_index in tqdm(list(splits)):\n",
    "    x_train, x_test = msgs[train_index], msgs[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    data_train = data[train_index]\n",
    "    data_test = data[test_index, 0]\n",
    "    \n",
    "    classifier = NaiveBayes()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    pred = classifier.predict(x_test)\n",
    "    \n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    \n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98620689655172411, 0.97241379310344822, 0.99310344827586206, 0.99307958477508651, 0.98961937716262971, 0.98961937716262971, 0.99307958477508651, 0.97923875432525953, 0.98961937716262971, 0.99307958477508651]\n",
      "[0.97586206896551719, 0.96551724137931039, 0.95862068965517244, 0.94809688581314877, 0.97231833910034604, 0.94809688581314877, 0.96193771626297575, 0.94463667820069208, 0.92387543252595161, 0.96193771626297575]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(nltk_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22e66932240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKEvSQ35v0ajlwxxXz8IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22e6ea243c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk_box = pd.DataFrame(nltk_accs)\n",
    "box = pd.DataFrame(accs)\n",
    "nltk_box.boxplot()\n",
    "box.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
